{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "hpctbX3SXD_E"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9H04G7QOHJ1"
      },
      "source": [
        "# **Importing necessary libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BQosAxrl56h"
      },
      "source": [
        "import nltk\n",
        "nltk.download('book')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4DsHE8oNQ1z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "outputId": "3b0fe694-a4b1-4cd7-c97a-bcfe0f9ce172"
      },
      "source": [
        "import numpy as np\n",
        "from nltk.tokenize import word_tokenize\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import operator\n",
        "import gensim\n",
        "import string\n",
        "import re\n",
        "from keras.layers.recurrent import LSTM\n",
        "from keras.models import Model\n",
        "from keras.models import model_from_json\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Bidirectional\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers import Bidirectional,Concatenate\n",
        "from keras.layers import TimeDistributed\n",
        "from keras.layers import Dense, Activation ,Input\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.utils.data_utils import get_file"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'keras.layers.recurrent'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-6afd6a2771f6>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecurrent\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodel_from_json\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras.layers.recurrent'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpctbX3SXD_E"
      },
      "source": [
        "# **ATTENTION LAYER**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGjEedHUW2Nc"
      },
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "from tensorflow.python.keras.layers import Layer\n",
        "from tensorflow.python.keras import backend as K\n",
        "\n",
        "\n",
        "class AttentionLayer(Layer):\n",
        "    \"\"\"\n",
        "    This class implements Bahdanau attention (https://arxiv.org/pdf/1409.0473.pdf).\n",
        "    There are three sets of weights introduced W_a, U_a, and V_a\n",
        "     \"\"\"\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        super(AttentionLayer, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        assert isinstance(input_shape, list)\n",
        "        # Create a trainable weight variable for this layer.\n",
        "\n",
        "        self.W_a = self.add_weight(name='W_a',\n",
        "                                   shape=tf.TensorShape((input_shape[0][2], input_shape[0][2])),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "        self.U_a = self.add_weight(name='U_a',\n",
        "                                   shape=tf.TensorShape((input_shape[1][2], input_shape[0][2])),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "        self.V_a = self.add_weight(name='V_a',\n",
        "                                   shape=tf.TensorShape((input_shape[0][2], 1)),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "\n",
        "        super(AttentionLayer, self).build(input_shape)  # Be sure to call this at the end\n",
        "\n",
        "    def call(self, inputs, verbose=False):\n",
        "        \"\"\"\n",
        "        inputs: [encoder_output_sequence, decoder_output_sequence]\n",
        "        \"\"\"\n",
        "        assert type(inputs) == list\n",
        "        encoder_out_seq, decoder_out_seq = inputs\n",
        "        if verbose:\n",
        "            print('encoder_out_seq>', encoder_out_seq.shape)\n",
        "            print('decoder_out_seq>', decoder_out_seq.shape)\n",
        "\n",
        "        def energy_step(inputs, states):\n",
        "            \"\"\" Step function for computing energy for a single decoder state \"\"\"\n",
        "\n",
        "            assert_msg = \"States must be a list. However states {} is of type {}\".format(states, type(states))\n",
        "            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n",
        "\n",
        "            \"\"\" Some parameters required for shaping tensors\"\"\"\n",
        "            en_seq_len, en_hidden = encoder_out_seq.shape[1], encoder_out_seq.shape[2]\n",
        "            de_hidden = inputs.shape[-1]\n",
        "\n",
        "            \"\"\" Computing S.Wa where S=[s0, s1, ..., si]\"\"\"\n",
        "            # <= batch_size*en_seq_len, latent_dim\n",
        "            reshaped_enc_outputs = K.reshape(encoder_out_seq, (-1, en_hidden))\n",
        "            # <= batch_size*en_seq_len, latent_dim\n",
        "            W_a_dot_s = K.reshape(K.dot(reshaped_enc_outputs, self.W_a), (-1, en_seq_len, en_hidden))\n",
        "            if verbose:\n",
        "                print('wa.s>',W_a_dot_s.shape)\n",
        "\n",
        "            \"\"\" Computing hj.Ua \"\"\"\n",
        "            U_a_dot_h = K.expand_dims(K.dot(inputs, self.U_a), 1)  # <= batch_size, 1, latent_dim\n",
        "            if verbose:\n",
        "                print('Ua.h>',U_a_dot_h.shape)\n",
        "\n",
        "            \"\"\" tanh(S.Wa + hj.Ua) \"\"\"\n",
        "            # <= batch_size*en_seq_len, latent_dim\n",
        "            reshaped_Ws_plus_Uh = K.tanh(K.reshape(W_a_dot_s + U_a_dot_h, (-1, en_hidden)))\n",
        "            if verbose:\n",
        "                print('Ws+Uh>', reshaped_Ws_plus_Uh.shape)\n",
        "\n",
        "            \"\"\" softmax(va.tanh(S.Wa + hj.Ua)) \"\"\"\n",
        "            # <= batch_size, en_seq_len\n",
        "            e_i = K.reshape(K.dot(reshaped_Ws_plus_Uh, self.V_a), (-1, en_seq_len))\n",
        "            # <= batch_size, en_seq_len\n",
        "            e_i = K.softmax(e_i)\n",
        "\n",
        "            if verbose:\n",
        "                print('ei>', e_i.shape)\n",
        "\n",
        "            return e_i, [e_i]\n",
        "\n",
        "        def context_step(inputs, states):\n",
        "            \"\"\" Step function for computing ci using ei \"\"\"\n",
        "            # <= batch_size, hidden_size\n",
        "            c_i = K.sum(encoder_out_seq * K.expand_dims(inputs, -1), axis=1)\n",
        "            if verbose:\n",
        "                print('ci>', c_i.shape)\n",
        "            return c_i, [c_i]\n",
        "\n",
        "        def create_inital_state(inputs, hidden_size):\n",
        "            # We are not using initial states, but need to pass something to K.rnn funciton\n",
        "            fake_state = K.zeros_like(inputs)  # <= (batch_size, enc_seq_len, latent_dim\n",
        "            fake_state = K.sum(fake_state, axis=[1, 2])  # <= (batch_size)\n",
        "            fake_state = K.expand_dims(fake_state)  # <= (batch_size, 1)\n",
        "            fake_state = K.tile(fake_state, [1, hidden_size])  # <= (batch_size, latent_dim\n",
        "            return fake_state\n",
        "\n",
        "        fake_state_c = create_inital_state(encoder_out_seq, encoder_out_seq.shape[-1])\n",
        "        fake_state_e = create_inital_state(encoder_out_seq, encoder_out_seq.shape[1])  # <= (batch_size, enc_seq_len, latent_dim\n",
        "\n",
        "        \"\"\" Computing energy outputs \"\"\"\n",
        "        # e_outputs => (batch_size, de_seq_len, en_seq_len)\n",
        "        last_out, e_outputs, _ = K.rnn(\n",
        "            energy_step, decoder_out_seq, [fake_state_e],\n",
        "        )\n",
        "\n",
        "        \"\"\" Computing context vectors \"\"\"\n",
        "        last_out, c_outputs, _ = K.rnn(\n",
        "            context_step, e_outputs, [fake_state_c],\n",
        "        )\n",
        "\n",
        "        return c_outputs, e_outputs\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        \"\"\" Outputs produced by the layer \"\"\"\n",
        "        return [\n",
        "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[1][2])),\n",
        "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[0][1]))\n",
        "        ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0AToszOEOVUG"
      },
      "source": [
        "# **Preparing Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6Yk-_PdOTWb"
      },
      "source": [
        "encoder_url = 'https://raw.githubusercontent.com/joshua-decoder/indian-parallel-corpora/master/te-en/training.te-en.en'\n",
        "encoder_path = get_file('encoder_data.txt', origin=encoder_url)\n",
        "\n",
        "with open(encoder_path) as encoder_file_:\n",
        "  total_encoder_docs = encoder_file_.readlines()\n",
        "print(total_encoder_docs[1000])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uta5HErApRr"
      },
      "source": [
        "decoder_url = 'https://raw.githubusercontent.com/joshua-decoder/indian-parallel-corpora/master/te-en/training.te-en.te'\n",
        "decoder_path = get_file('decoder_data.txt', origin=decoder_url)\n",
        "\n",
        "with open(decoder_path) as decoder_file_:\n",
        "  total_decoder_docs = decoder_file_.readlines()\n",
        "print(total_decoder_docs[1000])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBE_6w3rbSpD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "40e4dcb2-6548-44ec-9486-b77ad96930ad"
      },
      "source": [
        "encoder_docs=[]\n",
        "decoder_docs=[]\n",
        "\n",
        "for i in range(len(total_encoder_docs)):\n",
        "  #if(i%4 == 0  or i%4 ==3):\n",
        "    encoder_docs.append(total_encoder_docs[i])\n",
        "    decoder_docs.append(total_decoder_docs[i])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'total_encoder_docs' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-dc3752b329e7>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdecoder_docs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_encoder_docs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0;31m#if(i%4 == 0  or i%4 ==3):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mencoder_docs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_encoder_docs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'total_encoder_docs' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kVYtU7rLxVY"
      },
      "source": [
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"i'm\", \"i am\", text)\n",
        "    text = re.sub(r\"he's\", \"he is\", text)\n",
        "    text = re.sub(r\"she's\", \"she is\", text)\n",
        "    text = re.sub(r\"it's\", \"it is\", text)\n",
        "    text = re.sub(r\"that's\", \"that is\", text)\n",
        "    text = re.sub(r\"what's\", \"that is\", text)\n",
        "    text = re.sub(r\"where's\", \"where is\", text)\n",
        "    text = re.sub(r\"how's\", \"how is\", text)\n",
        "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
        "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
        "    text = re.sub(r\"\\'re\", \" are\", text)\n",
        "    text = re.sub(r\"\\'d\", \" would\", text)\n",
        "    text = re.sub(r\"\\'re\", \" are\", text)\n",
        "    text = re.sub(r\"won't\", \"will not\", text)\n",
        "    text = re.sub(r\"can't\", \"cannot\", text)\n",
        "    text = re.sub(r\"n't\", \" not\", text)\n",
        "    text = re.sub(r\"n'\", \"ng\", text)\n",
        "    text = re.sub(r\"'bout\", \"about\", text)\n",
        "    text = re.sub(r\"'til\", \"until\", text)\n",
        "    text = re.sub(r\"[-()\\\"#/@;:<>{}`+=~|.!?,]\", \"\", text)\n",
        "    return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxA3qxFlYASs"
      },
      "source": [
        "cleaned_encoder_docs=[]\n",
        "cleaned_decoder_input_docs=[]\n",
        "cleaned_decoder_output_docs=[]\n",
        "start_of_sentence=\"<s>\"\n",
        "end_of_sentence=\"<e>\"\n",
        "unknown_word=\"<unk>\"\n",
        "\n",
        "for i in range(len(encoder_docs)):\n",
        "  cleaned_encoder_sent=clean_text(encoder_docs[i])\n",
        "  cleaned_decoder_sent=clean_text(decoder_docs[i])\n",
        "\n",
        "  cleaned_decoder_input_sent=start_of_sentence + \" \" + cleaned_decoder_sent\n",
        "  cleaned_decoder_output_sent=cleaned_decoder_sent + \" \" + end_of_sentence\n",
        "\n",
        "  splitted_encoder_sent=cleaned_encoder_sent.split()\n",
        "  splitted_decoder_input_sent=cleaned_decoder_input_sent.split()\n",
        "  splitted_decoder_output_sent=cleaned_decoder_output_sent.split()\n",
        "\n",
        "  if(len(splitted_encoder_sent)<=50 and len(splitted_decoder_input_sent)<=50 and len(splitted_decoder_output_sent)<=50):\n",
        "    cleaned_encoder_docs.append(splitted_encoder_sent)\n",
        "    cleaned_decoder_input_docs.append(splitted_decoder_input_sent)\n",
        "    cleaned_decoder_output_docs.append(splitted_decoder_output_sent)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYyYOIZNfM-8"
      },
      "source": [
        "print(len(cleaned_encoder_docs))\n",
        "print(len(cleaned_decoder_input_docs))\n",
        "print(len(cleaned_decoder_output_docs))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYbJOLiYfY_3"
      },
      "source": [
        "extra_list=[]\n",
        "extra_list.append(unknown_word)\n",
        "cleaned_encoder_docs.append(extra_list)\n",
        "\n",
        "extra_list=[]\n",
        "extra_list.append(start_of_sentence)\n",
        "extra_list.append(unknown_word)\n",
        "cleaned_decoder_input_docs.append(extra_list)\n",
        "\n",
        "extra_list=[]\n",
        "extra_list.append(unknown_word)\n",
        "extra_list.append(end_of_sentence)\n",
        "\n",
        "cleaned_decoder_output_docs.append(extra_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxVeeG01gD-O"
      },
      "source": [
        "print(len(cleaned_encoder_docs))\n",
        "print(len(cleaned_decoder_input_docs))\n",
        "print(len(cleaned_decoder_output_docs))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHzAPcDmgb6w"
      },
      "source": [
        "encoder_word_model = gensim.models.Word2Vec(cleaned_encoder_docs, size=100, min_count=1, window=2, iter=100)\n",
        "encoder_pretrained_weights = encoder_word_model.wv.syn0\n",
        "encoder_vocab_size, encoder_features_size = encoder_pretrained_weights.shape\n",
        "\n",
        "decoder_word_model = gensim.models.Word2Vec(cleaned_decoder_input_docs + cleaned_decoder_output_docs, size=100, min_count=1, window=2, iter=100)\n",
        "decoder_pretrained_weights = decoder_word_model.wv.syn0\n",
        "decoder_vocab_size, decoder_features_size = decoder_pretrained_weights.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_DNTj41hJIG"
      },
      "source": [
        "print(encoder_word_model.wv.vocab[unknown_word].index)\n",
        "print(decoder_word_model.wv.vocab[unknown_word].index)\n",
        "print(len(encoder_word_model.wv.vocab))\n",
        "print(len(decoder_word_model.wv.vocab))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikiGv8NDhTJQ"
      },
      "source": [
        "encoder_data_x=np.zeros([len(cleaned_encoder_docs), 50], dtype=np.int32)                      # MAX SENTENCE LENGTH = 50 for source language\n",
        "decoder_input_data_x=np.zeros([len(cleaned_decoder_input_docs), 50], dtype=np.int32)          # MAX SENTENCE LENGTH = 50 for target language\n",
        "decoder_output_data_x=np.zeros([len(cleaned_decoder_output_docs), 50], dtype=np.int32)        # MAX SENTENCE LENGTH = 50 for target language\n",
        "\n",
        "for i, sentence in enumerate(cleaned_encoder_docs):\n",
        "  for t, word in enumerate(sentence):\n",
        "    encoder_data_x[i, t] = encoder_word_model.wv.vocab[word].index\n",
        "\n",
        "for i, sentence in enumerate(cleaned_decoder_input_docs):\n",
        "  for t, word in enumerate(sentence):\n",
        "    decoder_input_data_x[i, t] = decoder_word_model.wv.vocab[word].index\n",
        "\n",
        "for i, sentence in enumerate(cleaned_decoder_output_docs):\n",
        "  for t, word in enumerate(sentence):\n",
        "    decoder_output_data_x[i, t] = decoder_word_model.wv.vocab[word].index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXSR3N1KlAyM"
      },
      "source": [
        "encoder_input_data=np.asarray(encoder_data_x)\n",
        "decoder_input_data=np.asarray(decoder_input_data_x)\n",
        "decoder_output_data=np.asarray(decoder_output_data_x)\n",
        "\n",
        "print(cleaned_encoder_docs[0])\n",
        "print(encoder_input_data[0])\n",
        "\n",
        "print(cleaned_decoder_input_docs[0])\n",
        "print(decoder_input_data[0])\n",
        "\n",
        "print(cleaned_decoder_output_docs[0])\n",
        "print(decoder_output_data[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJEXRJ_68o4Q"
      },
      "source": [
        "hidden_features=256"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fJn69cpmF1n"
      },
      "source": [
        "encoder_inputs=Input(shape=(50, ))\n",
        "encoder_embedding_layer = Embedding(input_dim = encoder_vocab_size,output_dim = encoder_features_size,weights=[encoder_pretrained_weights])\n",
        "encoder_embeddings=encoder_embedding_layer(encoder_inputs)\n",
        "encoder_LSTM = Bidirectional(LSTM(units=hidden_features, return_state=True))\n",
        "encoder_outputs, forward_h, forward_c, backward_h, backward_c = encoder_LSTM(encoder_embeddings)\n",
        "state_h = Concatenate()([forward_h, backward_h])\n",
        "state_c = Concatenate()([forward_c, backward_c])\n",
        "\n",
        "\n",
        "decoder_inputs = Input(shape=(50, ))\n",
        "decoder_embedding_layer = Embedding(input_dim = decoder_vocab_size,output_dim = decoder_features_size,weights=[decoder_pretrained_weights])\n",
        "decoder_embeddings=decoder_embedding_layer(decoder_inputs)\n",
        "decoder_LSTM = LSTM(units=hidden_features*2, return_state=True, return_sequences=True)\n",
        "decoder_outputs, _h, _c = decoder_LSTM(decoder_embeddings, initial_state=[state_h, state_c])\n",
        "\n",
        "\n",
        "outputs = Dense(decoder_vocab_size, activation='softmax')(decoder_outputs)\n",
        "\n",
        "\n",
        "model = Model([encoder_inputs, decoder_inputs], outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGjBZmHS-d0N"
      },
      "source": [
        "json_file = open('/content/model_4_ex (4).json', 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "model = model_from_json(loaded_model_json)\n",
        "# load weights into new model\n",
        "model.load_weights(\"/content/model_4_ex (6).h5\")\n",
        "print(\"Loaded model from disk\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qV6PDAI6nrJR"
      },
      "source": [
        "print(model.summary())\n",
        "\n",
        "model.compile(optimizer='rmsprop', loss ='sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmmCq9YbZQNo"
      },
      "source": [
        "10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hS15fCL9OU-"
      },
      "source": [
        "history = model.fit([encoder_input_data, decoder_input_data], decoder_output_data, epochs=5, batch_size=64)\n",
        "\n",
        "model_json = model.to_json()\n",
        "with open(\"model_4_ex_bi.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "\n",
        "model.save_weights(\"model_4_ex_bi.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_HT2WyzgFll"
      },
      "source": [
        "encoder_inputs=Input(shape=(50, ))\n",
        "encoder_embedding_layer = model.get_layer('embedding')\n",
        "encoder_embeddings=encoder_embedding_layer(encoder_inputs)\n",
        "encoder_LSTM=model.get_layer('bidirectional')\n",
        "encoder_outputs, forward_h, forward_c, backward_h, backward_c = encoder_LSTM(encoder_embeddings)\n",
        "state_h = Concatenate()([forward_h, backward_h])\n",
        "state_c = Concatenate()([forward_c, backward_c])\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "\n",
        "decoder_state_input_h = Input(shape=(hidden_features*2,))\n",
        "decoder_state_input_c = Input(shape=(hidden_features*2,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "single_input=Input(shape=(1,))\n",
        "decoder_embedding_layer=model.get_layer('embedding_1')\n",
        "embeddings=decoder_embedding_layer(single_input)\n",
        "decoder_LSTM=model.get_layer('lstm_1')\n",
        "decoder_outputs, _h, _c = decoder_LSTM(embeddings, initial_state=decoder_states_inputs)\n",
        "decoder_states = [_h, _c]\n",
        "decoder_dense = model.get_layer('dense')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "decoder_model = Model([single_input] + decoder_states_inputs, [decoder_outputs] + decoder_states)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvgGLyUnpYas"
      },
      "source": [
        "encoder_states = [state_h, state_c]\n",
        "encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "\n",
        "decoder_state_input_h = Input(shape=(hidden_features,))\n",
        "decoder_state_input_c = Input(shape=(hidden_features,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "single_input=Input(shape=(1,))\n",
        "embeddings=decoder_embedding_layer(single_input)\n",
        "decoder_outputs, _h, _c = decoder_LSTM(embeddings, initial_state=decoder_states_inputs)\n",
        "decoder_states = [_h, _c]\n",
        "decoder_dense = model.get_layer('dense')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "decoder_model = Model([single_input] + decoder_states_inputs, [decoder_outputs] + decoder_states)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUalwGABCi6a"
      },
      "source": [
        "print(decoder_model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23hNUPAKqgjf"
      },
      "source": [
        "print(encoder_model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSbUGIQRs3dG"
      },
      "source": [
        "def translate(english_input):\n",
        "    x_input=np.zeros((1,50) ,dtype=np.int32)\n",
        "    cleaned_english_input=clean_text(english_input)\n",
        "    splitted_english_input=cleaned_english_input.split()\n",
        "    f=0\n",
        "    for word in splitted_english_input:\n",
        "      if(word not in encoder_word_model.wv.vocab):\n",
        "        x_input[0][f]=46567\n",
        "      else:\n",
        "        x_input[0][f]=encoder_word_model.wv.vocab[word].index\n",
        "      f=f+1\n",
        "\n",
        "    encoder_states = encoder_model.predict(x_input)\n",
        "\n",
        "    telugu_seq = np.zeros((1, 1) ,dtype=np.int32)\n",
        "    telugu_seq[0,0] = 0\n",
        "    telugu_output = \"\"\n",
        "\n",
        "    for i in range(50):\n",
        "      output_tokens, h, c = decoder_model.predict([telugu_seq] + encoder_states)\n",
        "      indx=np.argmax(output_tokens[0,0,:])\n",
        "\n",
        "      if (indx==1):\n",
        "        break\n",
        "\n",
        "      if (indx>0):\n",
        "        telugu_output=telugu_output+\" \"+decoder_word_model.wv.index2word[indx]\n",
        "\n",
        "      telugu_seq = np.zeros((1, 1) ,dtype=np.int32)\n",
        "      telugu_seq[0,0] = indx\n",
        "      encoder_states=[h,c]\n",
        "\n",
        "    return telugu_output\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pwQeuWyAXyg"
      },
      "source": [
        "j=200\n",
        "for i in range(len(encoder_docs)):\n",
        "  print(\"ENGLISH -------------\",encoder_docs[j])\n",
        "  print(\"TELUGU---------------\",translate(encoder_docs[j]))\n",
        "  j=j+4\n",
        "  print(\"\")\n",
        "  if(i==10):\n",
        "    break\n",
        "text=\"After freedom, the Indian government is taken Police action on Nizam samsthanam after this action Hyderabad is arranged as state of these places.\"\n",
        "print(\"ENGLISH -------------\",text)\n",
        "print(\"TELUGU---------------\",translate(text))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfk3-Ij6Sd2X"
      },
      "source": [
        "text=\"thousands of villages in krishna,guntur sunk in the flow of krishna river.\"\n",
        "print(\"ENGLISH -------------\",text)\n",
        "print(\"TELUGU---------------\",translate(text))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zX7DhnImDqLo"
      },
      "source": [
        "for i in range(len(total_training_en)):\n",
        "  if(len(clean_text(total_training_en[i]).split())>50):\n",
        "    continue\n",
        "  print(\"ENGLISH -------------\",total_training_en[i])\n",
        "  print(\"TELUGU---------------\",translate(total_training_en[i]))\n",
        "  print(\"\")\n",
        "  if(i>10):\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fk2bvgdwJZKO"
      },
      "source": [
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "predicted_docs=[]\n",
        "actual_docs=[]\n",
        "\n",
        "for i in range(len(total_training_en)):\n",
        "  if(len(clean_text(total_training_en[i]).split())>50):\n",
        "    continue\n",
        "  telugu=translate(total_training_en[i])\n",
        "\n",
        "  predicted_docs.append(telugu.split())\n",
        "  if(i<len(total_training_te_docs)):\n",
        "    actual_docs.append(clean_text(total_training_te_docs[i]).split())\n",
        "\n",
        "score=0\n",
        "for sentence in predicted_docs:\n",
        "  score = score +  sentence_bleu(actual_docs,sentence)\n",
        "\n",
        "print(score/len(predicted_docs))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lW3WoHPNrh4"
      },
      "source": [
        "print(\"BLEU SCORE FOR LSTM MODEL WITHOUT ATTENTION   ------>  \",score/len(predicted_docs))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}